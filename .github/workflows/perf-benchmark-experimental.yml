name: Performance benchmark experimental

on:
  schedule:
    - cron: '0 5 * * *'
  workflow_dispatch:

permissions:
  id-token: write
  actions: write

jobs:
  filter-tests:
    runs-on: ubuntu-latest
    outputs:
      matrix_p150: ${{ steps.set-perf-benchmarks.outputs.matrix_p150 }}
      matrix_p150_skip: ${{ steps.set-perf-benchmarks.outputs.matrix_p150_skip }}
      matrix_n150_accuracy: ${{ steps.set-perf-benchmarks.outputs.matrix_n150_accuracy }}
      matrix_n150_accuracy_skip: ${{ steps.set-perf-benchmarks.outputs.matrix_n150_accuracy_skip }}
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        repository: 'tenstorrent/tt-forge'
        fetch-depth: 1
        ref: ${{ github.ref }}
        submodules: 'recursive'

    - name: Filter Matrix
      id: set-perf-benchmarks
      shell: bash
      run: |
        # Filter for regular p150 tests
        result=$(python .github/workflows/filter-test-matrix.py \
          .github/workflows/perf-bench-matrix.json \
          "tt-forge")

        matrix=$(echo $result | jq -r -c '.matrix')
        matrix_p150=$(echo $result | jq -r -c '.matrix | map(select(."runs-on" | contains("p150")))')

        matrix_p150_skip="false"

        if [ "$matrix_p150" == "[]" ]; then
          matrix_p150_skip="true"
        fi

        echo "matrix_p150=$matrix_p150" >> $GITHUB_OUTPUT
        echo "matrix_p150_skip=$matrix_p150_skip" >> $GITHUB_OUTPUT

        # Filter for n150 accuracy tests
        # Call filter-test-matrix.py with --sh-runner flag to map n150 to shared runners
        result_sh=$(python .github/workflows/filter-test-matrix.py \
          .github/workflows/perf-bench-matrix.json \
          "tt-forge" \
          --sh-runner)

        # Filter by: runs-on contains "n150" AND accuracy-testing == true
        matrix_n150_accuracy=$(echo $result_sh | jq -r -c '.matrix | map(select((."runs-on" | contains("n150")) and (.["accuracy-testing"] == true)))')

        matrix_n150_accuracy_skip="false"

        if [ "$matrix_n150_accuracy" == "[]" ]; then
          matrix_n150_accuracy_skip="true"
        fi

        echo "matrix_n150_accuracy=$matrix_n150_accuracy" >> $GITHUB_OUTPUT
        echo "matrix_n150_accuracy_skip=$matrix_n150_accuracy_skip" >> $GITHUB_OUTPUT

  run-p150-perf-benchmarks:
    needs: filter-tests
    if: ${{ needs.filter-tests.outputs.matrix_p150_skip == 'false' }}
    secrets: inherit
    uses: ./.github/workflows/call-perf-test.yml
    with:
      matrix: ${{ needs.filter-tests.outputs.matrix_p150 }}
      docker-image: "ghcr.io/tenstorrent/tt-xla-slim:nightly-latest"

  run-n150-accuracy-benchmarks:
    needs: filter-tests
    if: ${{ needs.filter-tests.outputs.matrix_n150_accuracy_skip == 'false' }}
    secrets: inherit
    uses: ./.github/workflows/call-perf-test.yml
    with:
      matrix: ${{ needs.filter-tests.outputs.matrix_n150_accuracy }}
      docker-image: "ghcr.io/tenstorrent/tt-xla-slim:nightly-latest"

  produce-data:
    needs:
      - run-p150-perf-benchmarks
      - run-n150-accuracy-benchmarks
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: checkout repository
        uses: actions/checkout@v4
      - name: Trigger produce_data.yml
        uses: ./.github/actions/trigger-workflow
        env:
          GH_TOKEN: ${{ github.token }}
        with:
          workflow_name: "produce_data.yml"
          wait: false
          wait_for_run_url: true
          json_params: '{"run_id": "${{ github.run_id }}", "run_attempt": "${{ github.run_attempt }}", "sleep": "10" }'
