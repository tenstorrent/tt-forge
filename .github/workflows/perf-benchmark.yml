name: Performance benchmark

on:
  workflow_dispatch:
    inputs:
      docker-image:
        description: "Docker image used in tests"
        required: false
        type: string
        default: "ghcr.io/tenstorrent/tt-forge/tt-forge-slim:dev20250701"
  workflow_call:
    inputs:
      docker-image:
        description: "Docker image used in tests"
        required: true
        type: string
      project:
        description: "Project where to find new version of wheel"
        required: false
        type: string
      run_id:
        description: "Workflow ID to use for the new version of wheel"
        required: false
        type: string
      ref:
        description: "Git ref to checkout"
        required: false
        type: string

jobs:
  run-perf-benchmarks:
    container:
      image: ${{ inputs.docker-image }}
      options: --device /dev/tenstorrent --user root
      volumes:
        - /dev/hugepages:/dev/hugepages
        - /dev/hugepages-1G:/dev/hugepages-1G
        - /etc/udev/rules.d:/etc/udev/rules.d
        - /lib/modules:/lib/modules
        - /opt/tt_metal_infra/provisioning/provisioning_env:/opt/tt_metal_infra/provisioning/provisioning_env
        - /usr/local/bin:/usr/local/bin
        - /mnt/dockercache:/mnt/dockercache

    # tt-torch reqs are not needed by tt-torch, but rather by benchmarking infra, should be moved elsewhere: https://github.com/tenstorrent/tt-forge/issues/177
    strategy:
      fail-fast: false
      matrix:
        build: [
          { runs-on: "n150", project: "tt-forge-fe", name: "llama",             dir: "LlamaModel",                   bs: 1,  lp: 32, df: 'float32',  ts: 'na',           libreq: "libgl1-mesa-glx libglib2.0-0" },
          { runs-on: "n150", project: "tt-forge-fe", name: "mnist_linear",      dir: "MNISTLinear",                  bs: 32, lp: 32, df: 'float32',  ts: 'na', },
          { runs-on: "n150", project: "tt-forge-fe", name: "resnet_hf",         dir: "ResNetForImageClassification", bs: 8,  lp: 32, df: 'bfloat16', ts: 'classification', libreq: "libgl1-mesa-glx libglib2.0-0" },
          { runs-on: "n150", project: "tt-forge-fe", name: "mobilenetv2_basic", dir: "MobileNetv2Basic",             bs: 8,  lp: 32, df: 'bfloat16', ts: 'classification', libreq: "libgl1-mesa-glx libglib2.0-0" },
          { runs-on: "n150", project: "tt-forge-fe", name: "efficientnet_timm", dir: "EfficientNetTimmB0",           bs: 6,  lp: 32, df: 'bfloat16', ts: 'classification', libreq: "libgl1-mesa-glx libglib2.0-0" },
          { runs-on: "n150", project: "tt-forge-fe", name: "segformer",         dir: "Segformer",                    bs: 1,  lp: 32, df: 'float32',  ts: 'na',           libreq: "libgl1-mesa-glx libglib2.0-0" },
          { runs-on: "n150", project: "tt-forge-fe", name: "vit",               dir: "ViTBase",                      bs: 8,  lp: 32, df: 'float32',  ts: 'classification', libreq: "libgl1-mesa-glx libglib2.0-0" },
          { runs-on: "n150", project: "tt-forge-fe", name: "vovnet",            dir: "VovnetOSMR",                   bs: 16, lp: 32, df: 'bfloat16', ts: 'classification', libreq: "libgl1-mesa-glx libglib2.0-0" },
          { runs-on: "n150", project: "tt-forge-fe", name: "yolo_v4",           dir: "YOLOv4",                       bs: 1,  lp: 32, df: 'bfloat16', ts: 'na',           libreq: "libgl1-mesa-glx libglib2.0-0" },
          { runs-on: "n150", project: "tt-forge-fe", name: "yolo_v8",           dir: "YOLOv8",                       bs: 1,  lp: 32, df: 'bfloat16', ts: 'na',           libreq: "libgl1-mesa-glx libglib2.0-0" },
          { runs-on: "n150", project: "tt-forge-fe", name: "yolo_v9",           dir: "YOLOv9",                       bs: 1,  lp: 32, df: 'bfloat16', ts: 'na',           libreq: "libgl1-mesa-glx libglib2.0-0" },
          { runs-on: "n150", project: "tt-forge-fe", name: "yolo_v10",          dir: "YOLOv10",                      bs: 1,  lp: 32, df: 'bfloat16', ts: 'na',           libreq: "libgl1-mesa-glx libglib2.0-0" },
          { runs-on: "n150", project: "tt-forge-fe", name: "unet",              dir: "UNet",                         bs: 1,  lp: 32, df: 'bfloat16', ts: 'na',           libreq: "libgl1-mesa-glx libglib2.0-0" },
          { runs-on: "n150", project: "tt-torch",    name: "resnet",            dir: "",                             bs: 8,  lp: 32, df: 'default',  ts: 'na', pyreq: "loguru requests transformers datasets torchvision pytest ultralytics", libreq: "libgl1-mesa-glx libglib2.0-0" },
          { runs-on: "n150", project: "tt-xla",      name: "resnet",            dir: "",                             bs: 1,  lp: 32, df: 'default',  ts: 'na', pyreq: "pytest tqdm loguru requests transformers datasets flax torch" },
        ]
    runs-on:
      - ${{ matrix.build.runs-on }}
      - in-service

    name: "run-perf-benchmarks ${{matrix.build.project }}-${{matrix.build.name }} (${{ matrix.build.runs-on }}, ${{ matrix.build.bs }}, ${{ matrix.build.lp }})"
    steps:

    - uses: actions/checkout@v4
      with:
          fetch-depth: 1
          ref: ${{ inputs.ref || github.ref }}

    - name: Install system and python dependencies
      shell: bash
      run: |
        if [ "${{ matrix.build.project }}" == "tt-forge-fe" ]; then
          apt-get install -y -qq --no-install-recommends sqlite3
        fi
        if [ -n "${{ matrix.build.libreq }}" ]; then
          apt-get install -y -qq --no-install-recommends ${{ matrix.build.libreq }}
        fi

        source /home/forge/venv-${{ matrix.build.project }}/bin/activate
        if [ -n "${{ matrix.build.pyreq }}" ]; then
          pip install ${{ matrix.build.pyreq }}
        fi

    - name: Install upgraded wheel
      if: ${{ inputs.project && inputs.run_id }}
      uses: ./.github/actions/install-wheel
      with:
        project: ${{ inputs.project }}
        run_id: ${{ inputs.run_id }}

    - name: Fetch job id
      id: fetch-job-id
      uses: tenstorrent/tt-github-actions/.github/actions/job_id@main
      with:
        job_name: "run-perf-benchmarks ${{matrix.build.project }}-${{matrix.build.name }} (${{ matrix.build.runs-on }}, ${{ matrix.build.bs }}, ${{ matrix.build.lp }})"

    - name: Set reusable strings
      id: strings
      shell: bash
      env:
        JOB_ID: ${{ steps.fetch-job-id.outputs.job_id }}
      run: |
        echo "work-dir=$(pwd)" >> "$GITHUB_OUTPUT"
        echo "build-output-dir=$(pwd)/build" >> "$GITHUB_OUTPUT"
        echo "perf_report_path=$(pwd)/benchmark_reports" >> "$GITHUB_OUTPUT"

    # - name: Git safe dir
    #   run: git config --global --add safe.directory ${{ steps.strings.outputs.work-dir }}

    # ttrt version (sha) should be taken from release metadata or something
    - name: Download ttrt wheel
      uses: dawidd6/action-download-artifact@v6
      with:
        workflow_conclusion: success
        workflow: on-push.yml
        branch: main
        name: "(ttrt-whl|install-artifacts)-tracy"
        name_is_regexp: true
        repo: tenstorrent/tt-mlir
        check_artifacts: true
        path: ./

    - name: Untar ttmlir install directory
      shell: bash
      run: |
        mv install-artifacts-tracy/ install/
        cd install
        tar xvf artifact.tar
        cd ..

    - name: Run Perf Benchmark
      shell: bash
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
        HF_HOME: /mnt/dockercache/huggingface
        HF_HUB_DISABLE_PROGRESS_BARS: 1
      run: |
        mkdir -p ${{ steps.strings.outputs.perf_report_path }}
        source /home/forge/venv-${{ matrix.build.project }}/bin/activate
        echo "Run perf benchmark"
        mkdir -p /__w/tt-forge/tt-forge/model_dir/${{ matrix.build.project }}/${{ matrix.build.name }}
        if [ "${{ matrix.build.project }}" == "tt-torch" ]; then
          export TT_TORCH_SAVE_MLIR=TTIR
        fi
        python benchmark/benchmark.py -p ${{ matrix.build.project}} -m ${{ matrix.build.name }} -bs ${{ matrix.build.bs }} -df ${{ matrix.build.df }} -lp ${{ matrix.build.lp }} -ts ${{ matrix.build.ts }} -o ${{ steps.strings.outputs.perf_report_path }}/benchmark_${{ matrix.build.project }}_e2e_${{ matrix.build.name }}_${{ matrix.build.bs }}_${{ matrix.build.lp }}_${{ steps.fetch-job-id.outputs.job_id }}.json
        if [ "${{ matrix.build.project }}" == "tt-torch" ]; then
          cp /__w/tt-forge/tt-forge/model_mlir/${{ matrix.build.name }}_ttir.mlir /__w/tt-forge/tt-forge/model_dir/${{ matrix.build.project }}/${{ matrix.build.name }}/ttir.mlir
        else
          cp ~/testify/ll-sw/${{ matrix.build.dir }}/mlir_reports/ttir.mlir /__w/tt-forge/tt-forge/model_dir/${{ matrix.build.project }}/${{ matrix.build.name }}/ttir.mlir
        fi
        echo "Remove system descriptor from ttir"
        python benchmark/device_perf.py -ct /__w/tt-forge/tt-forge/model_dir/${{ matrix.build.project }}/${{ matrix.build.name }}/ttir.mlir

    - name: Install and run TTRT
      # if: ${{ matrix.build.project != 'tt-torch' }}
      shell: bash
      run: |
        python -m venv ttrt-venv
        source ttrt-venv/bin/activate
        apt-get install -y -qq --no-install-recommends libtbb12
        apt-get install -y -qq --no-install-recommends libcapstone4
        pip install ttrt-whl-tracy/ttrt*.whl --force-reinstall
        pip install torch==2.3.0 --index-url https://download.pytorch.org/whl/cpu
        echo "save artifacts"
        ttrt query --save-artifacts
        if [ -z "${{ matrix.build.allow-fail }}" ]; then
          ./benchmark/compile_and_run.sh /__w/tt-forge/tt-forge/model_dir/${{ matrix.build.project }}/${{ matrix.build.name }}/ttir_out.mlir ${{ steps.strings.outputs.perf_report_path }}/benchmark_${{ matrix.build.project }}_e2e_${{ matrix.build.name }}_${{ matrix.build.bs }}_${{ matrix.build.lp }}_${{ steps.fetch-job-id.outputs.job_id }}.json
        else
          ./benchmark/compile_and_run.sh /__w/tt-forge/tt-forge/model_dir/${{ matrix.build.project }}/${{ matrix.build.name }}/ttir_out.mlir ${{ steps.strings.outputs.perf_report_path }}/benchmark_${{ matrix.build.project }}_e2e_${{ matrix.build.name }}_${{ matrix.build.bs }}_${{ matrix.build.lp }}_${{ steps.fetch-job-id.outputs.job_id }}.json || true
        fi

    # - name: Sleep to debug container
    #   if: failure()
    #   run: |
    #     echo "Sleeping for 1 hour to debug container"
    #     sleep 3600

    - name: Upload Perf Report
      uses: actions/upload-artifact@v4
      if: success() || failure()
      with:
        name: perf-reports-${{ steps.fetch-job-id.outputs.job_id }}
        path: ${{ steps.strings.outputs.perf_report_path }}
