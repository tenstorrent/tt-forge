name: Performance benchmark

on:
  workflow_dispatch:

jobs:
  run-perf-benchmarks:
    container:
      image:  ubuntu:22.04 # "ghcr.io/tenstorrent/tt-mlir/tt-mlir-ci-ubuntu-22-04:latest"
      options: "--device /dev/tenstorrent/0"
      volumes:
        - /dev/hugepages:/dev/hugepages
        - /dev/hugepages-1G:/dev/hugepages-1G
        - /etc/udev/rules.d:/etc/udev/rules.d
        - /lib/modules:/lib/modules
        - /opt/tt_metal_infra/provisioning/provisioning_env:/opt/tt_metal_infra/provisioning/provisioning_env
        - /mnt/dockercache:/mnt/dockercache

    strategy:
      fail-fast: false
      matrix:
        build: [
          { runs-on: "n150", project: "tt-forge-fe", name: "llama",             dir: "LlamaModel", bs: 1, lp: 32 },
          # { runs-on: "n150", project: "tt-forge-fe", name: "mnist_linear",      dir: "MNISTLinear", bs: 32, lp: 32 },
          # { runs-on: "n150", project: "tt-forge-fe", name: "resnet_hf",         dir: "ResNetForImageClassification", bs: 3, lp: 32 },
          # { runs-on: "n150", project: "tt-forge-fe", name: "mobilenetv2_basic", dir: "MobileNetv2Basic", bs: 1, lp: 32 },
          # { runs-on: "n150", project: "tt-forge-fe", name: "efficientnet_timm", dir: "EfficientNetTimmB0", bs: 1, lp: 32 },
          # { runs-on: "n150", project: "tt-torch",    name: "resnet",            dir: "", bs: 8, lp: 32, require: "onnx onnxruntime" }
        ]
    runs-on:
      - ${{ matrix.build.runs-on }}
      - in-service

    name: "run-perf-benchmarks ${{matrix.build.project }}-${{matrix.build.name }} (${{ matrix.build.runs-on }}, ${{ matrix.build.bs }}, ${{ matrix.build.lp }})"
    steps:

    - uses: actions/checkout@v4
      with:
          sparse-checkout: |
            benchmark/
            pytest.ini
            conftest.py
            .test_durations
          fetch-depth: 1 # Fetch all history and tags

    - name: Install common tools and dependencies
      shell: bash
      run: |
        apt-get update -qq >/dev/null 2>&1
        apt-get install -y -qq --no-install-recommends \
          git \
          jq \
          curl \
          unzip \
          wget \
          ca-certificates
        # ttrt
        # apt-get install -y -qq --no-install-recommends \
        #   libmpich12
        if [ "${{ matrix.build.project }}" == "tt-forge-fe" ]; then
          apt-get install -y -qq --no-install-recommends \
            build-essential \
            libgl1-mesa-glx \
            sqlite3 \
            libopenmpi3 \
            libglib2.0-0
        fi
        if [ -n "${{ matrix.build.libreq }}" ]; then
          apt-get install -y -qq --no-install-recommends ${{ matrix.build.libreq }}
        fi

    - name: Fetch job id
      id: fetch-job-id
      # uses: tenstorrent/tt-github-actions/.github/actions/job_id@main
      # with:
      #   job_name: "run-perf-benchmarks ${{matrix.build.project }}-${{matrix.build.name }} (${{ matrix.build.runs-on }}, ${{ matrix.build.bs }}, ${{ matrix.build.lp }})"
      shell: bash
      run: |
        JOB_NAME="run-perf-benchmarks ${{matrix.build.project }}-${{matrix.build.name }} (${{ matrix.build.runs-on }}, ${{ matrix.build.bs }}, ${{ matrix.build.lp }})"
        workflow_id="${{ github.run_id }}"
        repo="tenstorrent/tt-forge"
        page=1
        per_page=90
        job_id=""

        set +e
        while true; do
            response=$(curl -s -H "Authorization: token ${{secrets.GH_TOKEN}}" \
                "https://api.github.com/repos/$repo/actions/runs/$workflow_id/jobs?per_page=$per_page&page=$page")
            res=$?
            if [ $res -ne 0 ]; then
                echo "Error ($res) fetching jobs for workflow ID $workflow_id."
                exit $res
            fi

            job_id=$(echo "$response" | jq -r --arg JOB_NAME "$JOB_NAME" '.jobs[] | select(.name | contains($JOB_NAME)) | .id')

            if [ -n "$job_id" ]; then
                echo "Job ID for job name '$JOB_NAME' is: $job_id"
                break
            fi

            # Check if we have more pages to fetch
            next_page=$(echo "$response" | jq -r '.total_count')
            if [ "$((page * per_page))" -ge "$next_page" ]; then
                break
            fi

            page=$((page + 1))
        done

        if [ -z "$job_id" ]; then
            echo "Job name '$JOB_NAME' not found in workflow ID $workflow_id."
            exit 1
        fi

        echo "job_id=$job_id" >> $GITHUB_OUTPUT

    - name: Set reusable strings
      id: strings
      shell: bash
      env:
        JOB_ID: ${{ steps.fetch-job-id.outputs.job_id }}
      run: |
        echo "work-dir=$(pwd)" >> "$GITHUB_OUTPUT"
        echo "build-output-dir=$(pwd)/build" >> "$GITHUB_OUTPUT"
        echo "perf_report_path=$(pwd)/benchmark_reports" >> "$GITHUB_OUTPUT"

    # - name: Git safe dir
    #   run: git config --global --add safe.directory ${{ steps.strings.outputs.work-dir }}

    # ttrt version (sha) should be taken from release metadata or something
    # - name: Download ttrt wheel
    #   uses: dawidd6/action-download-artifact@v6
    #   with:
    #     workflow_conclusion: success
    #     workflow: on-push.yml
    #     branch: main
    #     name: "(ttrt-whl|install-artifacts)-tracy"
    #     name_is_regexp: true
    #     repo: tenstorrent/tt-mlir
    #     check_artifacts: true
    #     path: ./

    # - name: Untar ttmlir install directory
    #   shell: bash
    #   run: |
    #     mv install-artifacts-tracy/ install/
    #     cd install
    #     tar xvf artifact.tar
    #     cd ..

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'

    - name: Download project releases
      uses: robinraju/release-downloader@v1
      with:
        latest: true
        preRelease: true
        tarBall: false
        zipBall: false
        fileName: '*.whl'

    - name: Install wheels
      shell: bash
      run: |
        if [ "${{ matrix.build.project }}" == "tt-forge-fe" ]; then
          python -m venv tt-forge-fe-venv
          source tt-forge-fe-venv/bin/activate
          pip install tvm*.whl
          pip install forge*.whl
        elif [ "${{ matrix.build.project }}" == "tt-torch" ]; then
          python -m venv tt-torch-venv
          source tt-torch-venv/bin/activate
          pip install tt_torch*.whl
          pip install ttmlir*.whl
        else
          echo "Unknown project: ${{ matrix.build.project }}"
          exit 1
        fi
        if [ -n "${{ matrix.build.require }}" ]; then
          pip install ${{ matrix.build.require }}
        fi

    - name: Run Perf Benchmark
      shell: bash
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
        HF_HOME: /mnt/dockercache/huggingface
        HF_HUB_DISABLE_PROGRESS_BARS: 1
      run: |
        mkdir -p ${{ steps.strings.outputs.perf_report_path }}
        source ${{ matrix.build.project }}-venv/bin/activate
        python benchmark/benchmark.py -p ${{ matrix.build.project}} -m ${{ matrix.build.name }} -bs ${{ matrix.build.bs }} -lp ${{ matrix.build.lp }} -o ${{ steps.strings.outputs.perf_report_path }}/benchmark_${{ matrix.build.project }}_e2e_${{ matrix.build.name }}_${{ matrix.build.bs }}_${{ matrix.build.lp }}_${{ steps.fetch-job-id.outputs.job_id }}.json
        if [ -n "${{ matrix.build.dir }}" ]; then
          python benchmark/create_ttir.py ~/testify/ll-sw/${{ matrix.build.dir }}/mlir_reports/ttir.mlir
        fi

    # - name: Install and run TTRT
    #   if: ${{ matrix.build.project != 'tt-torch' }}
    #   shell: bash
    #   run: |
    #     python -m venv ttrt-venv
    #     source ttrt-venv/bin/activate
    #     pip install ttrt-whl-tracy/ttrt*.whl --force-reinstall
    #     pip install torch==2.3.0 --index-url https://download.pytorch.org/whl/cpu
    #     echo "save artifacts"
    #     ttrt query --save-artifacts
    #     if [ -z "${{ matrix.build.allow-fail }}" ]; then
    #       ./benchmark/compile_and_run.sh ~/testify/ll-sw/${{ matrix.build.dir }}/mlir_reports/ttir_out.mlir ${{ steps.strings.outputs.perf_report_path }}/benchmark_${{ matrix.build.project }}_e2e_${{ matrix.build.name }}_${{ matrix.build.bs }}_${{ matrix.build.lp }}.json # _${{ steps.fetch-job-id.outputs.job_id }}.json
    #     else
    #       ./benchmark/compile_and_run.sh ~/testify/ll-sw/${{ matrix.build.dir }}/mlir_reports/ttir_out.mlir ${{ steps.strings.outputs.perf_report_path }}/benchmark_${{ matrix.build.project }}_e2e_${{ matrix.build.name }}_${{ matrix.build.bs }}_${{ matrix.build.lp }}_.json || true # ${{ steps.fetch-job-id.outputs.job_id }}.json || true
    #     fi

    - name: Upload Perf Report
      uses: actions/upload-artifact@v4
      if: success() || failure()
      with:
        name: perf-reports-${{ steps.fetch-job-id.outputs.job_id }}
        path: ${{ steps.strings.outputs.perf_report_path }}
